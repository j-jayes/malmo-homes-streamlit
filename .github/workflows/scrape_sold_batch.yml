name: Scrape All Sold Properties (Area-Based)

on:
  workflow_dispatch:
    inputs:
      min_area:
        description: 'Min living area (mÂ²) - for testing use 400'
        required: false
        type: number
        default: 0
      max_area:
        description: 'Max living area (mÂ²) - for testing use 500'
        required: false
        type: number
        default: 500
      initial_step:
        description: 'Initial step size (mÂ²)'
        required: false
        type: number
        default: 50
      max_pages:
        description: 'Max pages per area range'
        required: false
        type: number
        default: 50

permissions:
  contents: write
  issues: write

jobs:
  scrape-all-areas:
    runs-on: ubuntu-latest
    timeout-minutes: 350  # 5h 50m (under 6h limit)
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH
      
      - name: Install dependencies with uv
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -e ".[scraping]"
      
      - name: Install Playwright and browsers
        run: |
          source .venv/bin/activate
          playwright install chromium --with-deps
      
      - name: Setup virtual display (Xvfb)
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb
          # Start Xvfb in background
          export DISPLAY=:99
          Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
          sleep 3
          echo "DISPLAY=:99" >> $GITHUB_ENV
      
      - name: Configure git for commits
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
      
      - name: Run adaptive area scraper with progress tracking
        id: scrape
        run: |
          source .venv/bin/activate
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Starting adaptive area-based scraping"
          echo "Area range: ${{ github.event.inputs.min_area }}-${{ github.event.inputs.max_area }}mÂ²"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Run adaptive area scraper
          python scripts/scrape_all_areas.py \
            --headless \
            --min-area ${{ github.event.inputs.min_area }} \
            --max-area ${{ github.event.inputs.max_area }} \
            --initial-step ${{ github.event.inputs.initial_step }} \
            --max-pages ${{ github.event.inputs.max_pages }} \
            --output-dir data/raw/area_ranges || {
              echo "âŒ Scraping failed"
              echo "Committing progress before exit..."
              git add data/raw/area_ranges/*.csv data/raw/area_ranges/*.json data/.hemnet_session.json 2>/dev/null || true
              git diff --staged --quiet || git commit -m "data: partial area scrape (failed)"
              git push || true
              exit 1
            }
          
          # Commit progress incrementally (scraper saves after each range)
          git add data/raw/area_ranges/*.csv data/raw/area_ranges/*.json data/raw/sold_properties_all_areas.csv data/.hemnet_session.json 2>/dev/null || true
          
          if ! git diff --staged --quiet; then
            echo "ðŸ’¾ Committing scraped data..."
            git commit -m "data: sold property links via area filtering"
            git push || {
              echo "âš ï¸  Push failed, will retry at end"
            }
            echo "âœ… Committed data"
          fi
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Scraping complete!"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        env:
          DISPLAY: ${{ env.DISPLAY }}
      
      - name: Check outputs
        run: |
          if [ -d "data/raw/area_ranges" ]; then
            echo "âœ… Output directory exists"
            echo "ðŸ“Š Files created:"
            ls -lh data/raw/area_ranges/
            
            # Count total unique properties
            if [ -f "data/raw/sold_properties_all_areas.csv" ]; then
              TOTAL=$(tail -n +2 data/raw/sold_properties_all_areas.csv | wc -l)
              echo "Total unique properties: $TOTAL"
            fi
            
            # Show progress
            if [ -f "data/raw/area_ranges/progress.json" ]; then
              echo "Progress:"
              cat data/raw/area_ranges/progress.json
            fi
          else
            echo "âŒ Output directory not found"
            exit 1
          fi
      
      - name: Final push (ensure everything is committed)
        run: |
          # Pull any changes from parallel workflows
          git config pull.rebase false
          git pull origin main || echo "No remote changes to pull"
          
          # Add any remaining files
          git add data/raw/area_ranges/*.csv data/raw/area_ranges/*.json data/raw/sold_properties_all_areas.csv data/.hemnet_session.json 2>/dev/null || true
          
          # Final commit if needed
          if ! git diff --staged --quiet; then
            git commit -m "data: final area-based scrape commit"
            git push
          else
            echo "âœ… Everything already committed"
          fi
      
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sold-properties-all-areas
          path: |
            data/raw/area_ranges/*.csv
            data/raw/area_ranges/*.json
            data/raw/sold_properties_all_areas.csv
          retention-days: 30
      
      - name: Create summary
        if: success()
        run: |
          echo "## âœ… Area-Based Scraping Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "data/raw/area_ranges/progress.json" ]; then
            TOTAL=$(cat data/raw/area_ranges/progress.json | jq -r '.total_properties')
            RANGES=$(cat data/raw/area_ranges/progress.json | jq -r '.completed_ranges | length')
            echo "**Total properties:** $TOTAL" >> $GITHUB_STEP_SUMMARY
            echo "**Area ranges completed:** $RANGES" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ðŸš¨ Area-based scraping failed`,
              body: `The area-based sold properties scraping workflow failed.\n\nCheck the [workflow run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details.\n\n**Next steps:**\n- Review the logs for Cloudflare blocks\n- Check \`data/raw/area_ranges/progress.json\` to see which ranges completed\n- Re-run the workflow to resume from last checkpoint\n- The scraper has built-in resume capability`,
              labels: ['automation', 'scraping', 'sold-properties', 'bug']
            })
